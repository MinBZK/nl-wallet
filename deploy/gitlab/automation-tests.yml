automation-compile-check:
  rules: !reference [.merge-request, rules]
  script:
    - java -version
    - cd uiautomation
    - ./gradlew --no-daemon compileTestKotlin

scheduled-automation-tests-trigger:
  rules:
    - !reference [.default-branch, rules]
  needs:
    - job: deploy-apps-ont
      artifacts: false
      optional: true
  trigger:
    include:
      - local: .gitlab-ci.yml
  variables:
    SCHEDULED: automation
  when: manual
  allow_failure: true

.run-automation-tests-base:
  extends: .env-k8s
  before_script:
    - BROWSERSTACK_USER=$(kubectl get secret nl-wallet-browserstack -o jsonpath='{.data.user}' | base64 --decode)
    - export BROWSERSTACK_USER
    - BROWSERSTACK_KEY=$(kubectl get secret nl-wallet-browserstack -o jsonpath='{.data.key}' | base64 --decode)
    - export BROWSERSTACK_KEY
    - java -version
    - cd uiautomation
    - set -euxo pipefail
  variables:
    APP_IDENTIFIER: "nl.ictu.edi.wallet.latest"
    ENABLE_BROWSERSTACK_A11Y_CHECKS: false

.run-automation-tests-common-setup:
  resource_group: automation-tests
  extends: .run-automation-tests-base
  needs:
    - job: build-env-ont
      artifacts: true
      optional: true
  artifacts:
    name: uiautomation
    when: always
    paths:
      - uiautomation/build/test-results/**/*.xml
      - uiautomation/build/allure-results
      - uiautomation/build/reports
    reports:
      junit: uiautomation/build/test-results/**/*.xml

.run-automation-tests-default:
  extends: .run-automation-tests-common-setup
  script:
    - mv browserstack-config/browserstack-oneplus12r-14-NL.yml ./browserstack.yml
    - ./gradlew --no-daemon --info --stacktrace test --tests $TESTS
      -Dtest.config.remote=true
      -Dfile.encoding=UTF-8 || true
    # Allow failure in tests and pass when there are test results (Quality Time should report on failed test)
    - compgen -G "build/test-results/test/*.xml"
  rules:
    - !reference [.on-schedule-automation, rules]

run-automation-tests-publish-results:
  rules: !reference [.run-automation-tests-default, rules]
  needs:
    - { job: run-automation-card-and-history-tests }
    - { job: run-automation-disclosure-tests }
    - { job: run-automation-introduction-tests }
    - { job: run-automation-issuance-tests }
    - { job: run-automation-menu-and-settings-tests }
    - { job: run-automation-open-app-tests }
    - { job: run-automation-security-tests }
  script:
    - deploy/bin/store-artifact-zip.sh qt/quality-time/junit-results/e2e.zip uiautomation/build/test-results/test/*.xml
    - deploy/bin/store-artifact-zip.sh qt/quality-time/allure-results/e2e.zip uiautomation/build/allure-results/*

run-automation-card-and-history-tests:
  extends: .run-automation-tests-default
  variables:
    TESTS: "suite.CardsAndHistoryTestSuite"

run-automation-disclosure-tests:
  extends: .run-automation-tests-default
  variables:
    TESTS: "suite.DisclosureTestSuite"

run-automation-introduction-tests:
  extends: .run-automation-tests-default
  variables:
    TESTS: "suite.IntroductionTestSuite"

run-automation-issuance-tests:
  extends: .run-automation-tests-default
  variables:
    TESTS: "suite.IssuanceTestSuite"

run-automation-menu-and-settings-tests:
  extends: .run-automation-tests-default
  variables:
    TESTS: "suite.MenuAndSettingsTestSuite"

run-automation-open-app-tests:
  extends: .run-automation-tests-default
  variables:
    TESTS: "suite.OpenAppTestSuite"

run-automation-security-tests:
  extends: .run-automation-tests-default
  variables:
    TESTS: "suite.SecurityTestSuite"

run-automation-notifications-tests:
  extends: .run-automation-tests-default
  variables:
    TESTS: "suite.NotificationsTestSuite"

run-automation-revocation-tests:
  extends: .run-automation-tests-default
  variables:
    TESTS: "suite.RevocationTestSuite"

run-automation-english-tests:
  extends: .run-automation-tests-common-setup
  script:
    - mv browserstack-config/browserstack-oneplus12r-14-EN.yml ./browserstack.yml
    - ./gradlew --no-daemon --info --stacktrace testEnglish
      -Dtest.config.remote=true
      -Dfile.encoding=UTF-8 || true
    # Allow failure in tests and pass when there are test results (Quality Time should report on failed test)
    - compgen -G "build/test-results/testEnglish/*.xml"
  rules:
    - !reference [.on-schedule-automation, rules]

.run-automation-a11y-batch:
  extends: .run-automation-tests-common-setup
  resource_group: null
  script:
    - mv browserstack-config/browserstack-oneplus12r-14-EN.yml ./browserstack.yml
    - ./gradlew --no-daemon --info --stacktrace testA11yBatch${BATCH_NUMBER}
      -Dtest.config.remote=true
      -Dfile.encoding=UTF-8 || true
  rules:
    - !reference [.on-schedule-trigger-scan, rules]
  variables:
    ENABLE_BROWSERSTACK_A11Y_CHECKS: true

run-automation-a11y-batch1-tests:
  extends: .run-automation-a11y-batch
  variables:
    BATCH_NUMBER: "1"

run-automation-a11y-batch2-tests:
  extends: .run-automation-a11y-batch
  needs:
    - job: run-automation-a11y-batch1-tests
      artifacts: false
  variables:
    BATCH_NUMBER: "2"

run-automation-a11y-batch3-tests:
  extends: .run-automation-a11y-batch
  needs:
    - job: run-automation-a11y-batch2-tests
      artifacts: false
  after_script:
    - echo "$CI_PIPELINE_ID" > a11y-build-name.txt
    - deploy/bin/store-artifact.sh a11y-build-name.txt qt/quality-time/a11y-results/a11y-build-name.txt
  variables:
    BATCH_NUMBER: "3"

browserstack-a11y-merge:
  extends: .run-automation-tests-base
  rules:
    - !reference [.on-schedule-scan, rules]
  variables:
    BROWSERSTACK_API_BASE: "https://api-app-accessibility.browserstack.com/automate/api/v1"
  script:
    - set +x
    - BUILD_NAME=$(mc cat qt/quality-time/a11y-results/a11y-build-name.txt)
    - BROWSERSTACK_PROJECT_ID=$(kubectl get secret nl-wallet-browserstack -o jsonpath='{.data.project_id}' | base64 --decode)
    # Get the last 2 builds for this project whose name == CI_PIPELINE_ID
    - |
      curl -sfS "${BROWSERSTACK_API_BASE}/project/${BROWSERSTACK_PROJECT_ID}/build?page_size=50&page=1" \
        -u "${BROWSERSTACK_USER}:${BROWSERSTACK_KEY}" \
        -o builds_raw.json

    - set -x
    - |
      echo "Filtering builds with name == BUILD_NAME (${BUILD_NAME}) and selecting the last 2…"
      jq --arg build_name "$BUILD_NAME" '
        {
          success,
          info,
          filters,
          builds: (
            [ .builds[]
              | select(.name == $build_name)
            ]
            | sort_by(.created_at)  # oldest → newest
            | reverse               # newest → oldest
            | .[:2]                 # take the last 2
          )
        }
      ' builds_raw.json > builds.json

      echo "Checking we have at least 2 matching builds…"
      jq -e '
        .success == true
        and (.builds | length >= 2)
      ' builds.json > /dev/null || {
        echo "ERROR: Need at least 2 builds with name == \"${BUILD_NAME}\". Got:"
        jq '{builds: [.builds[] | {id, th_build_id, name, created_at}]}' builds.json
        exit 1
      }

    # Create a combined summary
    - |
      echo "Creating combined summary…"
      jq -n --slurpfile r builds.json '
      def to_num:
        if type=="number" then .
        elif type=="string" then (tonumber? // 0)
        else 0 end;

      # severity_count can be: object, array of objects, null → return numeric for key
      def sev_get(o; k):
        if o == null then 0
        elif (o|type)=="object" then ((o[k] // 0) | to_num)
        elif (o|type)=="array"  then ((o | map(. [k] // 0 | to_num) | add) // 0)
        else 0 end;

      # sum a severity key across all builds
      def sev_sum(k):
        ([$r[0].builds[]
          | .issue_summary
          | if . == null then {} else . end
          | .severity_count
          | sev_get(.; k)
        ] | add) // 0;

      {
        project_id: ($r[0].builds[0].project_id // $r[0].project_id),
        generated_at: (now | strflocaltime("%Y-%m-%dT%H:%M:%SZ")),
        source: { page: $r[0].info.page, page_size: $r[0].info.page_size, count: $r[0].info.count },
        builds: [
          $r[0].builds[] |
          { id, th_build_id, name, created_at, started_at, status, issue_summary }
        ],
        summary: {
          build_count: ($r[0].builds | length),
          statuses: (
            reduce ($r[0].builds[] | .status) as $s ({}; .[$s] = ((.[$s] // 0) + 1) )
          ),
          totals: {
            total_issues: ([$r[0].builds[].issue_summary.total] | map((. // 0) | to_num) | add),
            scan_count:   ([$r[0].builds[].issue_summary.scan_count] | map((. // 0) | to_num) | add),
            severity_count: {
              minor:            sev_sum("minor"),
              moderate:         sev_sum("moderate"),
              serious:          sev_sum("serious"),
              critical:         sev_sum("critical"),
              failed_issues:    sev_sum("failed_issues"),
              needs_review:     sev_sum("needs_review"),
              confirmed:        sev_sum("confirmed"),
              hidden_issues:    sev_sum("hidden_issues"),
              duplicate_issues: sev_sum("duplicate_issues")
            }
          }
        }
      }' > combined_summary.json

    # Verify summary
    - |
      jq -e '
        (.builds | length == 2)
        and (.summary.build_count == 2)
        and (.summary.totals.total_issues | type == "number")
      ' combined_summary.json > /dev/null || {
        echo "ERROR: combined_summary.json sanity check failed"
        cat combined_summary.json || true
        exit 1
      }
  after_script:
    - deploy/bin/store-artifact-zip.sh qt/quality-time/a11y-results/a11y.zip uiautomation/combined_summary.json
  artifacts:
    name: browserstack-a11y
    when: always
    paths:
      - uiautomation/combined_summary.json

run-automation-smoke-test-ont:
  extends: .run-automation-tests-common-setup
  rules: !reference [.default-branch, rules]
  needs:
    - job: upload-browserstack-android-app
      artifacts: false
  script:
    - mv browserstack-config/browserstack-oneplus12r-14-NL.yml ./browserstack.yml
    - ./gradlew --no-daemon --info --stacktrace smokeTest
      -Dtest.config.remote=true
      -Dfile.encoding=UTF-8

run-automation-smoke-test-ios-ont:
  extends: .run-automation-tests-common-setup
  rules: !reference [.default-branch, rules]
  needs:
    - job: upload-browserstack-ios-app
      artifacts: false
    - job: deploy-apps-ont
      artifacts: false
  script:
    - mv browserstack-config/browserstack-Iphone16Pro-18-NL.yml ./browserstack.yml
    - ./gradlew --no-daemon --info --stacktrace smokeTestIOS
      -Dtest.config.remote=true
      -Dfile.encoding=UTF-8

browsertests-format-lint:
  rules: !reference [.default-or-merge-request, rules]
  image: "${HARBOR_REGISTRY}/${HARBOR_PROJECT}/nl-wallet-app-builder-ci-node:${BUILD_TAG}"
  script:
    - cd browsertests
    - npm ci --ignore-scripts
    - npm run format-check
    - npm run lint

.run-browsertest-common:
  image: "${HARBOR_REGISTRY}/${HARBOR_PROJECT}/nl-wallet-app-builder-ci-playwright:${BUILD_TAG}"
  extends: .env-k8s
  needs:
    - job: build-env-ont
      artifacts: true

run-wallet-web-browsertest-test-ont:
  extends: .run-browsertest-common
  rules:
    - !reference [.default-branch, rules]
  needs:
    - !reference [.run-browsertest-common, needs]
    - job: deploy-apps-ont
      artifacts: false
  script: |
    cd browsertests
    npm ci --ignore-scripts
    cd packages/wallet-web
    npx playwright install chromium webkit
    npm run test:ci
  after_script:
    - deploy/bin/store-artifact.sh browsertests/packages/wallet-web/test-results/results.xml qt/quality-time/junit-results/browsertest-wallet-web.xml
    - deploy/bin/store-artifact-zip.sh qt/quality-time/allure-results/browsertest-wallet-web.zip browsertests/packages/wallet-web/allure-results/*
  artifacts:
    name: browsertest-wallet-web
    when: always
    paths:
      - browsertests/packages/wallet-web/test-results/
      - browsertests/packages/wallet-web/allure-results/
    reports:
      junit: browsertests/packages/wallet-web/test-results/*.xml

run-fallback-pages-browsertest-test-ont:
  extends: .run-browsertest-common
  rules:
    - !reference [.default-branch, rules]
  needs:
    - !reference [.run-browsertest-common, needs]
    - job: deploy-apps-ont
      artifacts: false
  script: |
    cd browsertests
    npm ci --ignore-scripts
    cd packages/fallback-pages
    npx playwright install chromium webkit
    npm run test:ci
  after_script:
    - deploy/bin/store-artifact.sh browsertests/packages/fallback-pages/test-results/results.xml qt/quality-time/junit-results/browsertest-fallback-pages.xml
    - deploy/bin/store-artifact-zip.sh qt/quality-time/allure-results/browsertest-fallback-pages.zip browsertests/packages/fallback-pages/allure-results/*
  artifacts:
    name: browsertest-fallback-page
    when: always
    paths:
      - browsertests/packages/fallback-pages/test-results/
      - browsertests/packages/fallback-pages/allure-results/
    reports:
      junit: browsertests/packages/fallback-pages/test-results/*.xml

run-performance-test-ont:
  extends: .env-k8s
  rules:
    - !reference [.on-schedule-nightly-performance-test, rules]
    - !reference [.default-branch, rules]
  needs:
    - job: build-performance-test
      artifacts: true
    - job: deploy-apps-ont
      artifacts: false
      optional: true
  script:
    - START_TIME=$(date -u -d "-1 minute" "+%Y-%m-%d %H:%M:%S")
    - echo "Performance test starting, query range begins at $START_TIME"
    - wallet_core/tests_integration/run_performance_test.sh --skip-build 25
    - END_TIME=$(date -u -d "+1 minute" "+%Y-%m-%d %H:%M:%S")
    - echo "Performance test completed, query range ends at $END_TIME"
    - echo "START_TIME=$START_TIME" > perf-test-timeframe.txt
    - echo "END_TIME=$END_TIME" >> perf-test-timeframe.txt
  artifacts:
    paths:
      - perf-test-timeframe.txt
    when: on_success
  allow_failure: true

retrieve-performance-test-results-ont:
  extends: .env-k8s
  rules:
    - !reference [.on-schedule-nightly-performance-test, rules]
  needs:
    - job: run-performance-test-ont
      artifacts: true
  before_script:
    - python3 -m venv venv
    - source venv/bin/activate
    - pip3 install --no-cache-dir --upgrade pip
    - pip3 install --no-cache-dir -r deploy/qa-util/requirements.txt
  script:
    - START_TIME=$(grep START_TIME perf-test-timeframe.txt | cut -d'=' -f2-)
    - END_TIME=$(grep END_TIME perf-test-timeframe.txt | cut -d'=' -f2-)
    - echo "Using START_TIME=${START_TIME} and END_TIME=${END_TIME}"
    - |
      python3 deploy/qa-util/generate-k6-summary-from-grafana.py \
        --grafana-url "${SP_GRAFANA_TEST_API_URL}" \
        --api-token "${SP_GRAFANA_TEST_API_KEY}" \
        --start-time "$START_TIME" \
        --end-time "$END_TIME" \
        --output-file k6-summary.json
  after_script:
    - deploy/bin/store-artifact.sh k6-summary.json qt/quality-time/performance-results/k6-summary.json
  artifacts:
    paths:
      - k6-summary.json
    when: on_success
  variables:
    TESTS:

extract-manual-test-set:
  rules: !reference [.default-branch, rules]
  script:
    - ./deploy/qa-util/extract-manual-test-set.sh wallet_docs/functional-design/logical-test-cases.md manual-test-set.md
  when: manual
  allow_failure: true
  artifacts:
    name: manual-test-set
    when: always
    paths:
      - manual-test-set.md

ltc-coverage-check:
  rules:
    - !reference [.on-schedule-automation, rules]
  before_script:
    - python3 -m venv venv
    - source venv/bin/activate
    - pip3 install --no-cache-dir --upgrade pip
  script:
    - python3 deploy/qa-util/traceability-check.py
